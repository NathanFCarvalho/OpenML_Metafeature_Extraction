# Metafeature Extraction

This repository contains scripts for extracting metafeatures from 
datasets using the `pymfe` library and handling missing values using
`scikit-learn`. The code also includes functionality for saving the
extracted metafeatures and errors to JSONL files. 

This repository is designed to facilitate **large scale** metadata fetching 
for datasets from OpenML.


## Overview

### Metafeature Extraction

The `metafeature_extraction.py` script is designed to:
- Fetch datasets from OpenML.
- Handle missing values by imputing numerical columns with their mean and categorical columns with their mode.
- Extract metafeatures using the `pymfe` library.
- Save the extracted metafeatures to a CSV file and any errors encountered to a JSONL file.
- For big datasets, the `subsample` parameter, if set to True, creates a subsample of dataset that preserves
stratification and randomly selects a specified number of rows.

### Recommendation System

The `similarity_calculator.py` script is based on the sklearn 
nearest neighbor algorithm using the cosine metric and provides functionality to, using the ``x`` parameter (initially set to 5) nearest metafeaure values:
- Preprocess the metafeatures DataFrame by replacing infinite values, 
imputing missing values, and normalizing the data.
- Find the nearest neighbors using the `sklearn` library.

## Examples

### Metafeature Extraction

In order to extract metafeatures for a dataset in openml, 
you most use the `extract_metafeatures()` function, as it is shown:
```python
extract_metafeatures(dataset_id=2)
```
If the extraction is succesful, a csv file called `metafeatures.csv`
is created or updated. If an error occurs, a file called `errors.jsonl` containing the occured error and in which dataset is created or updated.


### Recommendation System
In order to see the ``k`` most similar datasets to a given one, the ``find_nearest_neighbors()`` function must be used. 
It takes as obligatory parameters a dataframe, such as the generated by the metafeature extraction tool and the dataset id.
```python
df = pd.read_csv('files/openml_metafeatures.csv')
find_nearest_neighbors(metafeature_dataframe=df, dataset_id=26)
```
In this example, I used the dataset nursery for this example, 
and supposed I called the metafeature dataframe df. This function returns two lists,
one list with the k closest datasets and one list with the
corresponding distances:
```python
(array([[2.22044605e-16, 2.22044605e-16, 2.22044605e-16, 1.06581410e-14,
         3.28388099e-03, 3.51377159e-03, 3.57437624e-03, 3.59268639e-03,
         3.59459105e-03, 4.11738386e-03, 4.50022660e-03, 4.50599478e-03,
         4.68712435e-03, 4.98536999e-03, 6.17525337e-03, 6.17525337e-03,
         6.35484738e-03, 6.35484738e-03, 6.38940212e-03, 6.39857896e-03]]),
 [959, 26, 43923, 1568, 42169, 45182, 335, 334, 333, 45183,
  45180, 43156, 45179, 45177, 491, 899, 42547, 43105, 43222, 43921])
  ```

In this example, the first 4 datasets (distances smaller than e-13) are, in fact, variations present in OpenML for the
dataset nursery. 
This code can be used to verify datasets which are variations on the same original one. For example, the underneath code is a code that can be used the repeated datasets inside the metadataset obtained from OpenML, using a similarity threshold of 1e-6.

```python
# Extract dataset IDs from the DataFrame
dataset_ids = list(df['dataset id'])  # Assuming the metadataset is called df and is stored in a DataFrame

# Initialize an empty list to hold groups of similar datasets
groups = [
    # Create a group of dataset IDs where the distance to ds is less than 1e-6
    [id for dist, id in zip(*find_nearest_neighbors(df, ds)) if dist < 1e-6]
    for ds in dataset_ids
]

# Filter out groups that have only one member (since they are not repeated)
groups = [group for group in groups if len(group) > 1]

# Initialize a set to keep track of seen groups and a list for unique groups
seen = set()
unique_lists = []

# Iterate through the groups to filter out duplicates
for group in groups:
    tuple_group = tuple(group)  # Convert the group to a tuple so it can be added to the set
    if tuple_group not in seen:  # If the group is not already in seen
        seen.add(tuple_group)    # Add it to seen
        unique_lists.append(group)

# Print the list of unique groups
print(unique_lists)
  ```

## Creating the `openml_metafeatures.csv` file

In order to create this file, datasets from OpenML were divised into small ones (< 50,000 instances) 
and big ones (>= 50,000). This division was done mainly for computational power reasons.

For datasets which had a target column, the `extract_metafeatures()` runs PyMFE normally.
If a dataset does not have a target column, it runs PyMFE without specifying a target column, which results in 
fewer metafeatures.

There are some datasets on OpenML which have multiple target columns. For them, 
I chose to run as if they had no target column.

The csv file contains only small datasets, with and without target columns. Bigger datasets were not
included.
